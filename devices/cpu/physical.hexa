// The Tofita Kernel
// Copyright (C) 2021  Oleg Petrenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

let physical_not_found = 0
// A lot of non-zero bits
// i.e. good in case of cosmic rays or something
// Completely reserved by hardware and kernel executable image
// Anything that is not defined considered to be PAGE_RESERVED
let page_reserved = 0xFF
let page_free = 0b1010
let page_full = 0b0101
let page_mask = 0b1111
// TODO mask user-mode pages differently than kernel-mode
// TODO let granular_partial = 0b1010
// TODO let granular_full = 0b1001
@inline fun down_bytes_to_pages(bytes) return ((bytes) >> 12)
// 4095 >> 12 == 0
// 4096 >> 12 == 1
// 8191 >> 12 == 1
// 8192 >> 12 == 2
let kernel_reserved_pages = 4096
// == 16 megabytes
// ^ this amount of memory cannot be allocated by user process
// to avoid system crash on our of memory

class PhysicalAllocator {
  private
	// Approx. 1 megabyte per each 4 gygabyte of RAM
	static UInt8 *buffer // TODO use bits, not bytes
	static UInt64 count
	static UInt64 countUser // count - kernel_reserved_pages
	static UInt64 available
	static UInt64 last

	// static fun init(const EfiMemoryMap *memoryMap, bufferVirtual: UInt64, ramPages: UInt64) {
	static fun init(const params: Pointer<KernelParams>) {
		buffer = (UInt8 *)params.physicalRamBitMaskVirtual
		const EfiMemoryMap *memoryMap = Pointer.of(params.efiMemoryMap)
		count = down_bytes_to_pages(params.ramBytes)
		countUser = count - kernel_reserved_pages
		last = physical_not_found

		memset((Void *)buffer, page_reserved, count)

		// Reserve UEFI memory map
		{
			const efi.EFI_MEMORY_DESCRIPTOR *descriptor = memoryMap.memoryMap
			let descriptorSize: UInt64 = memoryMap.descriptorSize
			var numberOfPages: UInt64 = 0

			var startOfMemoryMap: UInt64 = (memoryMap.memoryMap as! UInt64)
			var endOfMemoryMap: UInt64 = startOfMemoryMap + memoryMap.memoryMapSize
			var offset: UInt64 = startOfMemoryMap

			while (offset < endOfMemoryMap) {
				let kind = (descriptor.Type == efi.EfiConventionalMemory) ? page_free : page_reserved
				let where = down_bytes_to_pages(descriptor.PhysicalStart)
				let steps = descriptor.NumberOfPages

				if (kind == page_reserved)
					serialPrintf("[physical] Reserve %u pages from %u page\n", steps, where)

				var i: UInt64 = where
				while (i < steps) {
					// TODO bounds check - may be not in physycal area
					buffer[i] = kind
					i++
				}

				offset += descriptorSize
				descriptor = efi.getNextDescriptor(descriptor, descriptorSize)
			}
		}

		reserveOnePage(physical_not_found) // Ensure special case

		// Reserve bootloader buffer
		{
			var physical: UInt64 = params.physicalBuffer
			serialPrintf("[physical] Reserve %u bytes at %u of bootloader buffer\n", params.physicalBytes,
						 physical)
			var i: UInt64 = down_bytes_to_pages(params.physicalBytes) + 1
			while (i > 0) {
				i--
				reserveOnePage(physical + i * pageSize)
			}
		}

		{
			available = 0
			var i: UInt64 = count
			while (i > 0) {
				i--
				if (buffer[i] == page_free)
					available++
			}

			serialPrintf("[physical] Available %u of %u physical pages\n", available, count)
		}
	}

	// Note: takes real physical address, without mapped offset
	static fun reserveOnePage(physical: UInt64) {
		let where = down_bytes_to_pages(physical)
		buffer[where] = page_reserved
		if (last == where)
			last = physical_not_found
	}

// Must test as (buffer[_] != PAGE_FREE) == PAGE_RESERVED


	// 31-bit addressable, first 2 GB of RAM
	// Required by some hardware
	// We assume this by-default
	// static UInt64 allocateDmaPage2G() {}
	// TODO fill pages in reverse so I can traverse bitmap from zero?

	// Returns physical 64-bit address, not page number
	static UInt64 allocateOnePage() {
		if (last != physical_not_found) {
			let where = last
			last = physical_not_found
			return where * pageSize + (wholePhysicalStart as! UInt64)
		}

		var i: UInt64 = 0
		// TODO fast large-step outer search with uint64_t
		var steps: UInt64 = count // Avoid non-register access
		while (i < steps) {
			if (buffer[i] == page_free) {
				buffer[i] = page_full
				return i * pageSize + (wholePhysicalStart as! UInt64)
			}

			i++
		}

		serialPrintf("[physical] allocateOnePage == PHYSICAL_NOT_FOUND\n")
		return physical_not_found
	}

	static UInt64 allocateOnePagePreZeroed() {
		var result = allocateOnePage()
		if (result != physical_not_found)
			memset((Void *)result, 0, pageSize)
		return result
	}

	// Note: respects KERNEL_RESERVED_PAGES
	// TODO modify available
	// TODO each process should have some private extra pages (1 megabyte)
	// ^ means that available_now = (available - 1mb * process_count)
	static UInt64 allocateSafeUserspaceOnePagePreZeroed() {
		if (available > kernel_reserved_pages)
			return allocateOnePagePreZeroed()
		return physical_not_found
	}

	// TODO faster
	static UInt64 allocatePages(pages: UInt64) {
		// 0 or 1 == 1 page anyway
		if (pages < 2)
			return allocateOnePage()
		last = physical_not_found

		// Find largest free block
		var largest: UInt64 = 0
		var largestAt: UInt64 = 0

		{
			var current: UInt64 = 0
			var currentAt: UInt64 = 0
			var i: UInt64 = 0
			var steps: UInt64 = count // Avoid non-register access
			// TODO ^ same for buffer[]
			// TODO probably UInt32 is completely enough to represent pages
			while (i < steps) {
				// if (buffer[i] != PAGE_FREE) {
				//	if (current > largest) {
				//		largest = current
				//		largestAt = currentAt
				//		if (largest >= pages) break
				//	}
				//	current = 0
				//} else {
				//	if (current == 0) currentAt = i
				//	current++
				//}

				if (buffer[i] == page_free) {
					if (current == 0)
						currentAt = i
					current++
				}

				if (current >= pages) {
					largest = current
					largestAt = currentAt
					// if (largest >= pages)
					break
				}

				if (buffer[i] != page_free) {
					current = 0
				}

				i++
			}
			serialPrintf("[physical] allocatePages current %u\n", current)
			serialPrintf("[physical] allocatePages currentAt %u\n", currentAt)
		}

		if (largest >= pages) {
			var i: UInt64 = pages
			while (i > 0) {
				i--
				buffer[largestAt + i] = page_full
			}
			return largestAt * pageSize + (wholePhysicalStart as! UInt64)
		}

		serialPrintf("[physical] allocatePages %u pages == PHYSICAL_NOT_FOUND\n", pages)
		return physical_not_found
	}

	// Current granularity: 4096 bytes
	static UInt64 allocateBytes(bytes: UInt64) {
		// TODO
		return allocatePages(down_bytes_to_pages(bytes) + 1)
	}

	// Current granularity: xxx bytes
	static UInt64 allocateFileCacheBlock(bytes: UInt64) {
		// TODO
		// The idea is to use very fast wide search over bitmask
		// too quickly find large chunks of memory
		// for file caches
		// and quickly deallocate if memory is not enough for apps/kernel
		// (maybe even in semi-automated way within this memory allocator)
		// (another very small bitmask for disk caches?)
		return allocatePages(down_bytes_to_pages(bytes) + 1)
	}

	static fun freeOnePage(physical: UInt64) {
		let where = down_bytes_to_pages(physical - (wholePhysicalStart as! UInt64))
		// Bounds check
		if (physical <= wholePhysicalStart || where > count)
			return
		// Cosmic rays
		if (buffer[where] == page_full)
			buffer[where] = page_free
		last = where
	}

	static fun freePages(physical: UInt64, pages: UInt64) {
		// TODO
		freeOnePage(physical)
	}

	static fun freeBytes(physical: UInt64, bytes: UInt64) {
		// TODO
		freePages(physical, down_bytes_to_pages(bytes) + 1)
	}

	// Same mechanics as in garbage collector
	static fun freeIfNotUsed(physical: UInt64, bytes: UInt64) {
		// TODO
	}

	// Same mechanics as in garbage collector
	// Applies only on whole pages
	// Pointers should be 64-bit aligned
	static fun freeAllNotUsedPages() {
		// TODO
		// TODO return amount of freed pages
	}
}




UInt8 *PhysicalAllocator.buffer
UInt64 PhysicalAllocator.count
UInt64 PhysicalAllocator.last
UInt64 PhysicalAllocator.available
UInt64 PhysicalAllocator.countUser

UInt64 allocateBytes(bytes: UInt64) {
	return PhysicalAllocator.allocateBytes(bytes)
}
