// The Tofita Kernel
// Copyright (C) 2022-2023 Oleh Petrenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

// TODO as smart *simple* enum: special `PHYSICAL_NOT_FOUND = 0` and `PHYSICAL = ...`
let physical_not_found = 0u64
// A lot of non-zero bits
// i.e. good in case of cosmic rays or something
// Completely reserved by hardware and kernel executable image
// Anything that is not defined considered to be PAGE_RESERVED
let page_reserved = 0xFFu8
let page_free = 0b1010u8
let page_full = 0b0101u8
let page_mask = 0b1111u8
// TODO mask user-mode pages differently than kernel-mode
// TODO let granular_partial = 0b1010
// TODO let granular_full = 0b1001
// TODO should return UInt64, cause x86-64 supports a 48-bit virtual address space
// and 2^32 of 4096 is only exactly 2^44
// ^ UPDATE THE VIRTUAL PAGE ALLOCATOR ACCORDINGLY
@inline fun down_bytes_to_pages(bytes UInt64) UInt64 {
	return ((bytes) >> 12u64)
}
// 4095 >> 12 == 0
// 4096 >> 12 == 1
// 8191 >> 12 == 1
// 8192 >> 12 == 2
let kernel_reserved_pages UInt64 = 4096u64
// == 16 megabytes
// ^ this amount of memory cannot be allocated by user process
// to avoid system crash on our of memory

// TODO rename to just Physical
class PhysicalAllocator {
	// Approx. 1 megabyte per each 4 gigabyte of RAM
	static var buffer ArrayPointer<UInt8> // TODO use bits, not bytes
	static var count UInt64
	static var countUser UInt64 // count - kernel_reserved_pages
	static var available UInt64
	static var last UInt64
	// TODO those fields must have ` = default`

	// TODO does make sense at all?
	//static fun virtualToPhysical(virtual UInt64) UInt64 {
	//	return 0
	//}

	static fun physicalToVirtual(physical UInt64) UInt64 {
		return physical + wholePhysicalStart
	}

	static fun init(params UefiPayload) {
		buffer = params.physicalRamBitMaskVirtual as! ArrayPointer<UInt8>
		let memoryMap UefiMemoryMap = params.efiMemoryMap.ref
		count = down_bytes_to_pages(params.ramBytes)
		countUser = count - kernel_reserved_pages
		last = physical_not_found

		memset(buffer, page_reserved, count)

		// Reserve UEFI memory map
		{
			var descriptor EFI_MEMORY_DESCRIPTOR = memoryMap.memoryMap
			let descriptorSize UInt64 = memoryMap.descriptorSize
			var numberOfPages UInt64 = 0

			var startOfMemoryMap UInt64 = (memoryMap.memoryMap as! UInt64)
			var endOfMemoryMap UInt64 = startOfMemoryMap + memoryMap.memoryMapSize
			var offset UInt64 = startOfMemoryMap

			// TODO ensure that allocated in bootloader is reserved here (like initial PML4) or discarded
			while offset < endOfMemoryMap {
				let kind UInt8 = (descriptor.type == EFI_MEMORY_TYPE.EfiConventionalMemory) ? page_free : page_reserved
				let where = down_bytes_to_pages(descriptor.physicalStart)
				let steps = descriptor.numberOfPages

				if kind == page_reserved {
					serialPrintf("[physical] Reserve %u pages from %u page\n", steps, where)
				}

				var i UInt64 = where
				while i < steps {
					// TODO bounds check - may be not in physical area
					if i < count {
						buffer[i] = kind
					}
					i++
				}

				offset += descriptorSize
				descriptor = getNextDescriptor(descriptor, descriptorSize)
			}
		}

		reserveOnePage(physical_not_found) // Ensure special case

		// Reserve bootloader buffer
		{
			var physical UInt64 = params.physicalBuffer
			serialPrintf("[physical] Reserve %u bytes at %u of bootloader buffer\n", params.physicalBytes,
						 physical)
			var i UInt64 = down_bytes_to_pages(params.physicalBytes) + 1u64
			while i > 0 {
				i--
				reserveOnePage(physical + i * (pageSize as! UInt64))
			}
		}

		{
			available = 0
			var i UInt64 = count
			while i > 0 {
				i--
				if buffer[i] == page_free {
					available++
				}
			}

			serialPrintf("[physical] Available %u of %u physical pages\n", available, count)
		}
	}

	// Note: takes real physical address, without mapped offset
	static fun reserveOnePage(physical UInt64) {
		let where = down_bytes_to_pages(physical)
		buffer[where] = page_reserved
		if last == where {
			last = physical_not_found
		}
	}

	// TODO Must test as (buffer[_] != PAGE_FREE) == PAGE_RESERVED
	// 31-bit addressable, first 2 GB of RAM
	// Required by some hardware
	// We assume this by-default
	// static UInt64 allocateDmaPage2G() {}
	// TODO fill pages in reverse so I can traverse bitmap from zero?

	static fun resetCounter() {
		last = physical_not_found
	}

	// Returns physical 64-bit address, not page number
	static fun allocateOnePage() UInt64 {
		if last != physical_not_found {
			let where = last
			last = physical_not_found
			return where * (pageSize as! UInt64) + (wholePhysicalStart as! UInt64)
		}

		var i UInt64 = 0
		// TODO fast large-step outer search with uint64_t
		var steps UInt64 = count // Avoid non-register access
		while i < steps {
			if buffer[i] == page_free {
				buffer[i] = page_full
				return i * (pageSize as! UInt64) + (wholePhysicalStart as! UInt64)
			}

			i++
		}

		serialPrintf("[physical] allocateOnePage == PHYSICAL_NOT_FOUND\n")
		return physical_not_found
	}

	static fun allocateOnePagePreZeroed() UInt64 {
		var result = allocateOnePage()
		if result != physical_not_found {
			memset(result as! ArrayPointer<UInt8>, 0, pageSize)
		}
		return result
	}

	// Note: respects KERNEL_RESERVED_PAGES
	// TODO modify available
	// TODO each process should have some private extra pages (1 megabyte)
	// ^ means that available_now = (available - 1mb * process_count)
	static fun allocateSafeUserspaceOnePagePreZeroed() UInt64 {
		if available > kernel_reserved_pages {
			return allocateOnePagePreZeroed()
		}
		return physical_not_found
	}

	// TODO faster
	static fun allocatePages(pages UInt64) UInt64 {
		// 0 or 1 == 1 page anyway
		if pages < 2u64 {
			return allocateOnePage()
		}

		last = physical_not_found

		// Find largest free block
		var largest UInt64 = 0
		var largestAt UInt64 = 0

		{
			var current UInt64 = 0
			var currentAt UInt64 = 0
			var i UInt64 = 0
			var steps UInt64 = count // Avoid non-register access
			// TODO ^ same for buffer[]
			// TODO probably UInt32 is completely enough to represent pages
			while i < steps {
				// if buffer[i] != PAGE_FREE {
				//	if current > largest {
				//		largest = current
				//		largestAt = currentAt
				//		if largest >= pages { break }
				//	}
				//	current = 0
				//} else {
				//	if current == 0 { currentAt = i }
				//	current++
				//}

				if buffer[i] == page_free {
					if current == 0u64 {
						currentAt = i
					}
					current++
				}

				if current >= pages {
					largest = current
					largestAt = currentAt
					// if (largest >= pages)
					break
				}

				if buffer[i] != page_free {
					current = 0
				}

				i++
			}
			serialPrintf("[physical] allocatePages current %u\n", current)
			serialPrintf("[physical] allocatePages currentAt %u\n", currentAt)
		}

		if largest >= pages {
			var i UInt64 = pages
			while i > 0u64 {
				i--
				buffer[largestAt + i] = page_full
			}
			return largestAt * (pageSize as! UInt64) + (wholePhysicalStart as! UInt64)
		}

		serialPrintf("[physical] allocatePages %u pages == PHYSICAL_NOT_FOUND\n", pages)
		return physical_not_found
	}

	// Current granularity: 4096 bytes
	// TODO rename to allocateBytesRoundedToPages
	static fun allocateBytes(bytes UInt64) UInt64 {
		return allocatePages(down_bytes_to_pages(bytes) + 1u64)
	}

	// Current granularity: xxx bytes
	static fun allocateFileCacheBlock(bytes UInt64) UInt64 {
		// TODO
		// The idea is to use very fast wide search over bitmask
		// too quickly find large chunks of memory
		// for file caches
		// and quickly deallocate if memory is not enough for apps/kernel
		// (maybe even in semi-automated way within this memory allocator)
		// (another very small bitmask for disk caches?)
		return allocatePages(down_bytes_to_pages(bytes) + 1u64)
	}

	static fun freeOnePage(physical UInt64) {
		let where = down_bytes_to_pages(physical - (wholePhysicalStart as! UInt64))
		// Bounds check
		if physical <= wholePhysicalStart or where > count {
			return
		}

		// Cosmic rays
		if buffer[where] == page_full {
			buffer[where] = page_free
		}

		last = where
	}

	static fun freePages(physical UInt64, pages UInt64) {
		// TODO
		freeOnePage(physical)
	}

	static fun freeBytes(physical UInt64, bytes UInt64) {
		// TODO
		freePages(physical, down_bytes_to_pages(bytes) + 1u64)
		// TODO `u64` to just `1`
	}

	// Same mechanics as in garbage collector
	static fun freeIfNotUsed(physical UInt64, bytes UInt64) {
		// TODO
	}

	// Same mechanics as in garbage collector
	// Applies only on whole pages
	// Pointers should be 64-bit aligned
	static fun freeAllNotUsedPages() {
		// TODO
		// TODO return amount of freed pages
	}
}

fun allocateBytes(bytes UInt64) UInt64 {
	return PhysicalAllocator.allocateBytes(bytes)
}
