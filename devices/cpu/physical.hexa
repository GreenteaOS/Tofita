// The Tofita Kernel
// Copyright (C) 2020  Oleg Petrenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

let PHYSICAL_NOT_FOUND = 0
// A lot of non-zero bits
// i.e. good in case of cosmic rays or something
// Completely reserved by hardware and kernel executable image
// Anything that is not defined considered to be PAGE_RESERVED
#define PAGE_RESERVED 0xFF
#define PAGE_FREE 0b1010
#define PAGE_FULL 0b0101
#define PAGE_MASK 0b1111
// TODO mask user-mode pages differently than kernel-mode
// TODO #define GRANULAR_PARTIAL 0b1010
// TODO #define GRANULAR_FULL 0b1001
#define DOWN_BYTES_TO_PAGES(bytes) ((bytes) >> 12)
// 4095 >> 12 == 0
// 4096 >> 12 == 1
// 8191 >> 12 == 1
// 8192 >> 12 == 2
let KERNEL_RESERVED_PAGES = 4096
// == 16 megabytes
// ^ this amount of memory cannot be allocated by user process
// to avoid system crash on our of memory

class PhysicalAllocator {
  private
	// Approx. 1 megabyte per each 4 gygabyte of RAM
	static UInt8 *buffer // TODO use bits, not bytes
	static UInt64 count
	static UInt64 countUser // count - KERNEL_RESERVED_PAGES
	static UInt64 available
	static UInt64 last

  public
	// static fun init(const EfiMemoryMap *memoryMap, bufferVirtual: UInt64, ramPages: UInt64) {
	static fun init(const KernelParams *params) {
		buffer = (UInt8 *)params.physicalRamBitMaskVirtual
		const EfiMemoryMap *memoryMap = &params.efiMemoryMap
		count = DOWN_BYTES_TO_PAGES(params.ramBytes)
		countUser = count - KERNEL_RESERVED_PAGES
		last = PHYSICAL_NOT_FOUND

		memset((Void *)buffer, PAGE_RESERVED, count)

		// Reserve UEFI memory map
		{
			const efi.EFI_MEMORY_DESCRIPTOR *descriptor = memoryMap.memoryMap
			let descriptorSize: UInt64 = memoryMap.descriptorSize
			var numberOfPages: UInt64 = 0

			var startOfMemoryMap: UInt64 = (uint64_t)memoryMap.memoryMap
			var endOfMemoryMap: UInt64 = startOfMemoryMap + memoryMap.memoryMapSize
			var offset: UInt64 = startOfMemoryMap

			while (offset < endOfMemoryMap) {
				let kind = (descriptor.Type == efi.EfiConventionalMemory) ? PAGE_FREE : PAGE_RESERVED
				let where = DOWN_BYTES_TO_PAGES(descriptor.PhysicalStart)
				let steps = descriptor.NumberOfPages

				if (kind == PAGE_RESERVED)
					serialPrintf("[physical] Reserve %u pages from %u page\n", steps, where)

				var i: UInt64 = where
				while (i < steps) {
					// TODO bounds check - may be not in physycal area
					buffer[i] = kind
					i++
				}

				offset += descriptorSize
				descriptor = efi.getNextDescriptor(descriptor, descriptorSize)
			}
		}

		reserveOnePage(PHYSICAL_NOT_FOUND) // Ensure special case

		// Reserve bootloader buffer
		{
			var physical: UInt64 = params.physicalBuffer
			serialPrintf("[physical] Reserve %u bytes at %u of bootloader buffer\n", params.physicalBytes,
						 physical)
			var i: UInt64 = DOWN_BYTES_TO_PAGES(params.physicalBytes) + 1
			while (i > 0) {
				i--
				reserveOnePage(physical + i * PAGE_SIZE)
			}
		}

		{
			available = 0
			var i: UInt64 = count
			while (i > 0) {
				i--
				if (buffer[i] == PAGE_FREE)
					available++
			}

			serialPrintf("[physical] Available %u of %u physical pages\n", available, count)
		}
	}

	// Note: takes real physical address, without mapped offset
	static fun reserveOnePage(physical: UInt64) {
		let where = DOWN_BYTES_TO_PAGES(physical)
		buffer[where] = PAGE_RESERVED
		if (last == where)
			last = PHYSICAL_NOT_FOUND
	}

// Must test as (buffer[_] != PAGE_FREE) == PAGE_RESERVED
#undef PAGE_RESERVED

	// 31-bit addressable, first 2 GB of RAM
	// Required by some hardware
	// We assume this by-default
	// static UInt64 allocateDmaPage2G() {}
	// TODO fill pages in reverse so I can traverse bitmap from zero?

	// Returns physical 64-bit address, not page number
	static UInt64 allocateOnePage() {
		if (last != PHYSICAL_NOT_FOUND) {
			let where = last
			last = PHYSICAL_NOT_FOUND
			return where * PAGE_SIZE + (uint64_t)WholePhysicalStart
		}

		var i: UInt64 = 0
		// TODO fast large-step outer search with uint64_t
		var steps: UInt64 = count // Avoid non-register access
		while (i < steps) {
			if (buffer[i] == PAGE_FREE) {
				buffer[i] = PAGE_FULL
				return i * PAGE_SIZE + (uint64_t)WholePhysicalStart
			}

			i++
		}

		serialPrintf("[physical] allocateOnePage == PHYSICAL_NOT_FOUND\n")
		return PHYSICAL_NOT_FOUND
	}

	static UInt64 allocateOnePagePreZeroed() {
		var result = allocateOnePage()
		if (result != PHYSICAL_NOT_FOUND)
			memset((Void *)result, 0, PAGE_SIZE)
		return result
	}

	// Note: respects KERNEL_RESERVED_PAGES
	// TODO modify available
	// TODO each process should have some private extra pages (1 megabyte)
	// ^ means that available_now = (available - 1mb * process_count)
	static UInt64 allocateSafeUserspaceOnePagePreZeroed() {
		if (available > KERNEL_RESERVED_PAGES)
			return allocateOnePagePreZeroed()
		return PHYSICAL_NOT_FOUND
	}

	// TODO faster
	static UInt64 allocatePages(pages: UInt64) {
		// 0 or 1 == 1 page anyway
		if (pages < 2)
			return allocateOnePage()
		last = PHYSICAL_NOT_FOUND

		// Find largest free block
		var largest: UInt64 = 0
		var largestAt: UInt64 = 0

		{
			var current: UInt64 = 0
			var currentAt: UInt64 = 0
			var i: UInt64 = 0
			var steps: UInt64 = count // Avoid non-register access
			// TODO ^ same for buffer[]
			// TODO probably UInt32 is completely enough to represent pages
			while (i < steps) {
				// if (buffer[i] != PAGE_FREE) {
				//	if (current > largest) {
				//		largest = current
				//		largestAt = currentAt
				//		if (largest >= pages) break
				//	}
				//	current = 0
				//} else {
				//	if (current == 0) currentAt = i
				//	current++
				//}

				if (buffer[i] == PAGE_FREE) {
					if (current == 0)
						currentAt = i
					current++
				}

				if (current >= pages) {
					largest = current
					largestAt = currentAt
					// if (largest >= pages)
					break
				}

				if (buffer[i] != PAGE_FREE) {
					current = 0
				}

				i++
			}
			serialPrintf("[physical] allocatePages current %u\n", current)
			serialPrintf("[physical] allocatePages currentAt %u\n", currentAt)
		}

		if (largest >= pages) {
			var i: UInt64 = pages
			while (i > 0) {
				i--
				buffer[largestAt + i] = PAGE_FULL
			}
			return largestAt * PAGE_SIZE + (uint64_t)WholePhysicalStart
		}

		serialPrintf("[physical] allocatePages %u pages == PHYSICAL_NOT_FOUND\n", pages)
		return PHYSICAL_NOT_FOUND
	}

	// Current granularity: 4096 bytes
	static UInt64 allocateBytes(bytes: UInt64) {
		// TODO
		return allocatePages(DOWN_BYTES_TO_PAGES(bytes) + 1)
	}

	// Current granularity: xxx bytes
	static UInt64 allocateFileCacheBlock(bytes: UInt64) {
		// TODO
		// The idea is to use very fast wide search over bitmask
		// too quickly find large chunks of memory
		// for file caches
		// and quickly deallocate if memory is not enough for apps/kernel
		// (maybe even in semi-automated way within this memory allocator)
		// (another very small bitmask for disk caches?)
		return allocatePages(DOWN_BYTES_TO_PAGES(bytes) + 1)
	}

	static fun freeOnePage(physical: UInt64) {
		let where = DOWN_BYTES_TO_PAGES(physical - (uint64_t)WholePhysicalStart)
		// Bounds check
		if (physical <= WholePhysicalStart || where > count)
			return
		// Cosmic rays
		if (buffer[where] == PAGE_FULL)
			buffer[where] = PAGE_FREE
		last = where
	}

	static fun freePages(physical: UInt64, pages: UInt64) {
		// TODO
		freeOnePage(physical)
	}

	static fun freeBytes(physical: UInt64, bytes: UInt64) {
		// TODO
		freePages(physical, DOWN_BYTES_TO_PAGES(bytes) + 1)
	}

	// Same mechanics as in garbage collector
	static fun freeIfNotUsed(physical: UInt64, bytes: UInt64) {
		// TODO
	}

	// Same mechanics as in garbage collector
	// Applies only on whole pages
	// Pointers should be 64-bit aligned
	static fun freeAllNotUsedPages() {
		// TODO
		// TODO return amount of freed pages
	}
}

#undef PAGE_FULL
#undef PAGE_FREE
#undef PAGE_MASK
UInt8 *PhysicalAllocator.buffer
UInt64 PhysicalAllocator.count
UInt64 PhysicalAllocator.last
UInt64 PhysicalAllocator.available
UInt64 PhysicalAllocator.countUser

UInt64 allocateBytes(bytes: UInt64) {
	return PhysicalAllocator.allocateBytes(bytes)
}
